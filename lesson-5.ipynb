{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1XjeTzsz7_x"
   },
   "source": [
    "## Теоретическая часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gry2IYHKz8AE"
   },
   "source": [
    "#### 1. Ответьте на вопросы:  В чем принципиальное отличие гибридных рекомендательных систем от коллаборативной фильтрации?  Приведите 2-3 примера задач, в которых необходимо использовать гибридные системы.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FISrRJh6z7_4"
   },
   "source": [
    "Коллаборативная фильтрация вырабатывает рекомендации, основанные на модели предшествующего поведения пользователя. Эта модель может быть построена исключительно на основе поведения данного пользователя и с учетом поведения других пользователей со сходными характеристиками.\n",
    "Гибридные системы - это как правило комбинирование нескольких алгоритмов в рамках одной платформы. Такой подход позволяет минимизировать проблемы, присущие каждому используемому алгоритму в отдельности. Например, комбинируя коллаборативную фильтрацию и контентный подход мы можем избежать ограничений, свойственных каждой из систем в отдельности. \n",
    "\n",
    "Построение рекомендаций фильмов, построение рекомендательной системы большого онлайн магазина, построение рекомендательной системы для сервиса, предоставляющего услуги. Во всеъх этих задачах необходимо использовать гибридные системы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8JdZSBnz8AF"
   },
   "source": [
    "#### 2.  Прочитайте статью про поиск на hh.ru https://habr.com/ru/company/hh/blog/347276/ Нам интересна именно рекомендательная система, раздел \"Производительность системы\" можно пропустить Какие основные отличия предложенной системы от тех подходов, которые мы разбирали на семинарах? Какие проблемы могут возникнуть при выводе такой модели в продакшен?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E64QMf0Oz7_6"
   },
   "source": [
    "В модели используется ранжирование поисковых запросов. Ранжирование состоит из двух частей: линейной, которая отделяет подходящие вакансии от неподходящих и грубо ранжирует неподходящие и XGBoost, которая используется, чтобы более точно ранжировать подходящие. К полученным при ранжировании признакам добвляют признаки, сравнивающие тексты с учётом текстовых взаимодействий. Все это скормливают модели машинного обучения, которая на выходе дает вероятность отклика на вакансию. \n",
    "\n",
    "Система состоит из нескольких компонент и ее будет трудно тюнинговать. Так же достаточно трудоемка отладка такой модели и внасение в нее изменений. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kSXv81cz8AF"
   },
   "source": [
    "#### 3. На вебинаре мы рассматривали модель LightFM (https://making.lyst.com/lightfm/docs/lightfm.html). В работе Data Scientist'а важную часть занимает research - исследование существующих архитектур и разбор научных статей, в которых они описываются. Вам предлагается изчуть оригинальную статью про LightFM https://arxiv.org/pdf/1507.08439.pdf и ответить на следующие вопросы:  \n",
    "* 1) Какой датасет используют авторы?  \n",
    "* 2) Что используют в качестве признаков?  \n",
    "* 3) С какими моделями сравнивают LightFM? Опишите их основные идеи кратко  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNE5pEkJz7_6"
   },
   "source": [
    "1) первый датасет это рейтинги фильмов с MovieLens, второй датасет состоит из опубликованных вопросов и ответов на CrossValidated.\n",
    "\n",
    "2) Для первого датасета фильмы описаны по жанрам и снабжены вектором тегов. Каждая пара тег-фильм - это оценка релевантности (от 0 до 1), обозначающая, насколько точно данный тег описывает фильм. Все рейтинги ниже 4,0 (по шкале от 1 до 5) считаем отрицательными; все рейтинги больше или равные 4.0 положительными. Все теги с рейтингами ниже 0,8 отбрасываются для сохранения только наиболее релевантных тегов.\n",
    "\n",
    "Для второго датасета набор данных состоит из опубликованных вопросов и ответов. Каждый вопрос сопровождается одним или несколькими из 1032 уникальных тегов. Кроме того, есть метаданные пользователя, которые получают из раздела «Обо мне» в профилях пользователей. Цель рекомендации - задать пользователям вопросы, на которые они могут ответить. \n",
    "\n",
    "3)Сравнение производится следующимих моделей: \n",
    "* MF модель: обычная модель матричной факторизации со смещением для пользователя и смещением для продукта и сигмоидной функцией.\n",
    "* LSI-LR: модель, основанная на содержании. Матрица, содержащая количество слов в документе (строки представляют уникальные слова, а столбцы представляют каждый документ), строится из большого фрагмента текста. Далее делается SVD разложение этой матрицы для уменьшения количества строк при сохранении структуры сходства среди столбцов. Из разложения берутся скрытые параметры (темы документов). Каждому пользователю соответствует его вектор в пространстве всех тем. Затем по этим данным строится логистическая регрессия для каждого пользователя.\n",
    "* LSI-UP: гибридная модель, представляющая профили пользователей, как линейные комбинации векторов представляющих внутренние параметры продуктов. К этим векторам применяют скрытую семантическую индексацию (LSI) (фактически SVD разложение) и получают скрытые параметры (векторы) для пользователей и товаров.\n",
    "* LightFM (tags): модель LightFM, использующая только теги.\n",
    "* LightFM (tags + ids): модель LightFM, использующая как теги, так и инентификаторы товаров.\n",
    "* LightFM (tags + about): модель LightFM с использованием как пользовательских так и продуктовых признаков. Пользовательские признаки доступны только для набора данных CrossValidated. Признаки получаются обработкой раздела пользователей \"Обо мне\" с помощью представления \"мешок слов\"(HTML очищается от тегов и небуквенных символов, затем преобразовывается в нижний регистр и\n",
    "токенизируется на пробелах)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n19OhGm_z7_7"
   },
   "source": [
    "## Практическая часть\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9a2DNsNKz7_8",
    "outputId": "8e2537c9-16c8-4ebc-b321-f4bfa253b079"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightfm\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nHTovEfPz7_-"
   },
   "outputs": [],
   "source": [
    "# импорт модулей src.utils и src.recommender\n",
    "\n",
    "from src.utils import precision_at_k, prefilter_items, postfilter_items, popular_items, gen_dicts\n",
    "from src.recommender import get_similar_items_recommendation, get_similar_users_recommendation\n",
    "\n",
    "# читаем данные из файла\n",
    "data = pd.read_csv('transaction_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZnN3kRlz7__"
   },
   "source": [
    "### 1. Модуль SRC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKLq6JBxz8AA"
   },
   "source": [
    "На вебинаре было рассказано про модуль src. Он приложен в материалах. Скачайте его, изучите структуру, импортируйте функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5PtkoIlz8AB"
   },
   "source": [
    "### 2. Работа с признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U29uOLDNz8AC"
   },
   "source": [
    "У нас есть внешние данные. Что с ними не так? Чего не хватает?  \n",
    "\n",
    "Проведите исследование внешних данных и составьте какие-нибудь содержательные выводы.  \n",
    "Формально Вам нужно построить 3+ графиков (scatter plot, hist или что-то иное) и описать, что мы видим (например, товары такой-то категории болле часто покупаются в следующие дни недели или пользователи с большим достатком предпочитают такие-то товары).  \n",
    "Исследуйте те закономерности, которые Вам интересно, чем менее тривиальный вывод получается, тем лучше! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HYWWYQmz8AC"
   },
   "source": [
    "### 3. LightFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFZVbwN-z8AD"
   },
   "source": [
    "У этого алогритма есть множество параметров (item/user_alpha, loss, no_components).  \n",
    "Проведите эксперименты аналогично дз 3 (подберите гипперпараметры каким удобно способои и постройте графики)  \n",
    "На выходе необходимо получить pr@5 на валидации (последние 3 недели) > 2%  \n",
    "\n",
    "У Вас, скорее всего, возникнет проблема со временем обучения. Почему они возникает?    \n",
    "\n",
    "Попробуйте запустить алгоритм вообще без фичей или используйте только признаки с небольшим числом уникальных категорий. (item_features['commodity_desc'].unique() - 300 уникальных категорий - это очень много)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLnjWB6Lz8AD"
   },
   "source": [
    "### *Отбор признаков* * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3-DjadOz8AE"
   },
   "source": [
    "Все данные категориальные, при ohe кодировании для товаров признаков становится невероятно много.      \n",
    "Какие стратегии отбора признаков в классическом ML Вы знаете? Применимы ли они тут?  \n",
    "\n",
    "Попробйте какие-нибудь стратегии. Удалось ли улучшить качество?\n",
    "\n",
    " \\* *задание необязательно*\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
